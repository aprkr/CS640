Q2: 
Predictions:
	Latency: 80.2 + 20.3 + 60.2 = 160.7 ms
	Throughput: Sent: 20 Mbps, Receive: 18 Mbps
Actual:
	Latency: 161 ms
	Throughput: Sent: 20.9 Mbps, Receive: 18.6 Mbps

Latency is sum of latencies for L1, L2, and L3.
Throughput is limited by slowest link, L1 in this case

Q3:
Predictions:
	Two Pair:
		Latency: 160 ms
		Throughput: Sent: 10, Receive: 9
	Three Pair:
		Latency: 160 ms
		Throughput: Sent: 7, Receive: 6
Actual:
	Two Pair:
                Latency: 160 ms
                Throughput: Sent: 20.4/12.0, Receive: 18.2/10.6
        Three Pair:
                Latency: 160 ms
                Throughput: Sent: 19.7/9.3/6.3, Receive: 17.9/7.4/5.4

Latency is unaffected as expected, the links are not changed. However, throughput changes unexpectedly, whatever link is established first tends to be the fasted, while the re

Q4:
Predictions:
	h1-h4:
		Latency: 160
		Throughput: 20
	h5-h6:
		Latency: 40
		Throughput: 27
Actual:
	h1-h4:
		Latency: 160
		Throughput: Sent: 18.1, Receive: 16.4
	h5-h6:
		Latency: 40
		Throughput: Sent: 24.3, Receive: 21.6
Latency unaffected as expected. However throughput seems to be as follows, sum of h1-h4 and h5-h6 bandwidths is 45. But, L2 is 40, so L2 bandwidth is split proportionally. 
